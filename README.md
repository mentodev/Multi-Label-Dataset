# Multi-Label-Dataset
Here are the results i obtained by changing the Neural Networks

1) Activation of final Layer: Softmax
   loss: binary_crossentropy
   Train_Loss:0.1907
   Train_Acc: 0.9227

   Valid_loss: 0.3071
   Valid_acc: 0.8960

   number of epochs: 10

2) Activation of final Layer: Sigmoid
   loss: binary_crossentropy
   Train_Loss:0.1899
   Train_Acc: 0.9231

   Valid_loss: 0.2627
   Valid_acc: 0.9080

   number of epochs: 10

## however here when epochs is increased to 15, heavy overfitting 
	is observed